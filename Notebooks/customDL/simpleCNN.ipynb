{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7583926,"sourceType":"datasetVersion","datasetId":4414669}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"path = \"/kaggle/input/insectes-acoustique/\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-07T21:07:05.207662Z","iopub.execute_input":"2024-02-07T21:07:05.208311Z","iopub.status.idle":"2024-02-07T21:07:05.212635Z","shell.execute_reply.started":"2024-02-07T21:07:05.208279Z","shell.execute_reply":"2024-02-07T21:07:05.211655Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset\nimport os\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nfrom torch.utils.data import DataLoader, Subset\nfrom tqdm import tqdm\n\n\n# Création du Dataset de train\npath_global_5s = path + \"Dataset acoustique insectes/CSVs morceaux audio 5s/Audible/train_audible_recording_chunks.csv\"\ndf = pd.read_csv(path_global_5s)\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(df['label'])\nnb_classes = len(label_encoder.classes_)\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, directory, pd_directory, transform=None):\n        self.directory = directory\n        self.transform = transform\n        self.images_name = os.listdir(self.directory)\n        \n        self.images = []\n        for image_path in tqdm(os.listdir(self.directory)):\n            img_path = os.path.join(self.directory, image_path)\n            self.images.append(Image.open(img_path).convert('RGB'))\n        \n        df = pd.read_csv(pd_directory)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images_name[idx]\n        image = self.images[idx]\n        label = np.zeros(nb_classes)\n\n        a = img_name.split(\"_\")\n        chunk_initial_time = a[-2]\n        code_unique = \"_\".join(a[:-3])\n        \n        labels = df[(df[\"code_unique\"] == code_unique) & (df[\"chunk_initial_time\"] == int(chunk_initial_time))][\"label\"]\n        label[label_encoder.transform(labels)] = 1\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T21:07:07.637128Z","iopub.execute_input":"2024-02-07T21:07:07.637982Z","iopub.status.idle":"2024-02-07T21:07:07.788482Z","shell.execute_reply.started":"2024-02-07T21:07:07.637947Z","shell.execute_reply":"2024-02-07T21:07:07.787688Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n\n# Transformation pour normaliser les données et potentiellement redimensionner les images\ntransform = transforms.Compose([\n    transforms.Resize((775, 308)),  # Si vos images ne sont pas de la taille requise\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T21:07:10.800874Z","iopub.execute_input":"2024-02-07T21:07:10.801682Z","iopub.status.idle":"2024-02-07T21:07:10.806847Z","shell.execute_reply.started":"2024-02-07T21:07:10.801652Z","shell.execute_reply":"2024-02-07T21:07:10.805863Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset_path = path + \"Dataset acoustique insectes/S�lection morceaux audio 5s/Audible/train_spectro\"\ntrain_pd_directory = path + \"Dataset acoustique insectes/CSVs morceaux audio 5s/Audible/train_audible_recording_chunks.csv\"\ntrain_dataset = CustomImageDataset(train_dataset_path, train_pd_directory, transform=transform)\ntrain_data_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n\ntest_dataset_path = path + \"Dataset acoustique insectes/S�lection morceaux audio 5s/Audible/train_spectro\"\ntest_pd_directory = path + \"Dataset acoustique insectes/CSVs morceaux audio 5s/Audible/train_audible_recording_chunks.csv\"\ntest_dataset = CustomImageDataset(test_dataset_path, test_pd_directory, transform=transform)\ntest_data_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T21:07:12.404450Z","iopub.execute_input":"2024-02-07T21:07:12.405290Z","iopub.status.idle":"2024-02-07T21:08:30.507418Z","shell.execute_reply.started":"2024-02-07T21:07:12.405259Z","shell.execute_reply":"2024-02-07T21:08:30.506552Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 5003/5003 [00:39<00:00, 125.68it/s]\n100%|██████████| 5003/5003 [00:37<00:00, 131.83it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, datasets\nfrom tqdm import tqdm\n\n# Vérifiez si un GPU est disponible et définissez le device en conséquence\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes=70):\n        super(CustomCNN, self).__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        \n        # Adaptive pooling permet d'avoir une taille fixe de sortie pour le FC layer, indépendamment de la taille d'entrée\n        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 7 * 7, 1024)\n        self.fc2 = nn.Linear(1024, num_classes)\n        \n        # Dropout pour réduire l'overfitting\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.adaptive_pool(x)\n        x = x.view(-1, 128 * 7 * 7)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.fc2(x)\n        #x = F.softmax(x, dim=1)\n        return x\n\nnum_classes = 70\nweight = np.zeros(num_classes)\n\nfor _, labels in tqdm(train_data_loader, position=0):\n    weight += labels.numpy().sum(axis=0)\n\n# Initialisation du modèle, perte et optimiseur\nmodel = CustomCNN(num_classes=num_classes).to(device)  # Déplacez le modèle sur le GPU si disponible\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weight).to(device))\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10  # Définissez le nombre d'époques souhaité\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()  # Mode entraînement\n    train_loss = 0\n    print(f'{epoch}, training :')\n    for images, labels in tqdm(train_data_loader, position=0):\n        images, labels = images.to(device), labels.to(device)  # Déplacez les données et les cibles sur le GPU si disponible\n        \n        outputs = model(images)\n        loss = criterion(outputs.float(), labels.float())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    train_loss /= len(train_data_loader)\n    \n    \"\"\"model.eval()  # Mode évaluation\n    test_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_data_loader, position=0):\n            images, labels = images.to(device), labels.to(device)  # Déplacez les données et les cibles sur le GPU si disponible\n            outputs = model(images)\n            loss = criterion(outputs.float(), labels.float())\n            test_loss += loss.item()\n    \n    test_loss /= len(test_data_loader)\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\"\"\"\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T22:16:19.429329Z","iopub.execute_input":"2024-02-07T22:16:19.430243Z","iopub.status.idle":"2024-02-07T22:30:30.738744Z","shell.execute_reply.started":"2024-02-07T22:16:19.430208Z","shell.execute_reply":"2024-02-07T22:30:30.737307Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"100%|██████████| 157/157 [00:42<00:00,  3.68it/s]\n  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"0, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:21<00:00,  1.92it/s]\n 10%|█         | 1/10 [01:21<12:14, 81.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Train Loss: 1.9190\n1, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:21<00:00,  1.94it/s]\n 20%|██        | 2/10 [02:42<10:50, 81.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Train Loss: 1.5378\n2, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.94it/s]\n 30%|███       | 3/10 [04:03<09:27, 81.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Train Loss: 1.3932\n3, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.94it/s]\n 40%|████      | 4/10 [05:24<08:05, 81.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Train Loss: 1.2756\n4, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.95it/s]\n 50%|█████     | 5/10 [06:45<06:44, 80.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Train Loss: 1.1791\n5, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.95it/s]\n 60%|██████    | 6/10 [08:05<05:23, 80.79s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Train Loss: 1.0894\n6, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.95it/s]\n 70%|███████   | 7/10 [09:26<04:02, 80.72s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Train Loss: 1.0273\n7, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.94it/s]\n 80%|████████  | 8/10 [10:47<02:41, 80.75s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Train Loss: 0.9620\n8, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.94it/s]\n 90%|█████████ | 9/10 [12:07<01:20, 80.76s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Train Loss: 0.9067\n9, training :\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [01:20<00:00,  1.95it/s]\n100%|██████████| 10/10 [13:28<00:00, 80.85s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Train Loss: 0.8593\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialiser pour calculer l'accuracy\ncorrect_predictions = 0\nincorrect_predictions = 0\ntotal_predictions = 0\ntotal_predictions_made = 0\n\nnb_good_prediction = np.zeros(num_classes) #Nombre de fois où il devait être predit et où il a été prédit\nnb_bad_prediction = np.zeros(num_classes) #Nombre de fois où il devait pas être predit et où il a été prédit\nnb_no_prediction = np.zeros(num_classes) #Nombre de fois où il devait être predit et où il a pas été prédit\nnb_must_be_predited = np.zeros(num_classes) # Nombre de fois où il devait être predit\nnb_must_not_be_predited = np.zeros(num_classes) # Nombre de fois où il devait pas être predit\nnb_is_predicted = np.zeros(num_classes)\nnb_prediction = 0\n\nwith torch.no_grad():  # Désactive le calcul du gradient pour économiser de la mémoire et accélérer\n    for images, labels in tqdm(test_data_loader, position=0):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Obtenez les prédictions du modèle\n        outputs = model(images)\n        \n        # Appliquez un seuil pour convertir les probabilités en prédictions binaires\n        # Ici, on utilise 0.5 comme seuil, mais cela pourrait être ajusté en fonction de votre cas d'utilisation\n        predicted = (outputs > 0.99).float()\n        \n        nb_must_be_predited += labels.cpu().numpy().sum(axis=0)\n        nb_must_not_be_predited += (-labels + 1).cpu().numpy().sum(axis=0)\n        nb_good_prediction += ((predicted == 1) & (labels == 1)).cpu().numpy().sum(axis=0)\n        nb_bad_prediction += ((predicted == 1) & (labels == 0)).cpu().numpy().sum(axis=0)\n        nb_no_prediction += ((predicted == 0) & (labels == 1)).cpu().numpy().sum(axis=0)\n        nb_is_predicted += predicted.cpu().numpy().sum(axis=0)\n        nb_prediction += predicted.shape[0]\n        \n\"\"\"        # Calculer le nombre de prédictions correctes\n        # Note: Les opérations sont effectuées en booléen, puis converties en float pour le calcul de la moyenne\n        correct_predictions += (predicted == labels).float().sum()\n        incorrect_predictions += (predicted != labels).float().sum()\n        total_predictions += torch.numel(labels)\n        total_predictions_made += torch.numel(predicted)\n\n# Calcul de l'accuracy moyenne\naccuracy = correct_predictions / total_predictions\nerror_rate  = incorrect_predictions / total_predictions\nprint(f'Accuracy: {accuracy.item()}, Error_rate : {error_rate.item()}')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:22:39.228097Z","iopub.execute_input":"2024-02-07T23:22:39.228965Z","iopub.status.idle":"2024-02-07T23:23:38.048644Z","shell.execute_reply.started":"2024-02-07T23:22:39.228931Z","shell.execute_reply":"2024-02-07T23:23:38.047759Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stderr","text":"100%|██████████| 157/157 [00:58<00:00,  2.67it/s]\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"\"        # Calculer le nombre de prédictions correctes\\n        # Note: Les opérations sont effectuées en booléen, puis converties en float pour le calcul de la moyenne\\n        correct_predictions += (predicted == labels).float().sum()\\n        incorrect_predictions += (predicted != labels).float().sum()\\n        total_predictions += torch.numel(labels)\\n        total_predictions_made += torch.numel(predicted)\\n\\n# Calcul de l'accuracy moyenne\\naccuracy = correct_predictions / total_predictions\\nerror_rate  = incorrect_predictions / total_predictions\\nprint(f'Accuracy: {accuracy.item()}, Error_rate : {error_rate.item()}')\""},"metadata":{}}]},{"cell_type":"code","source":"a = nb_good_prediction / nb_must_be_predited\nb = nb_bad_prediction / nb_must_not_be_predited\nc = nb_no_prediction / nb_must_be_predited\nd = nb_is_predicted / nb_must_be_predited\n\nprint(\"predit-label\")\nprint(\"classe \\t 1-1 \\t 1-0 \\t 0-1 \\t nb de fois predite / nb fois où il doit l'être\")\nfor i in range(len(nb_must_be_predited)):\n    print(f'{i} \\t {a[i]:.2f} \\t {b[i]:.2f} \\t {c[i]:.2f} \\t {d[i]:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:24:15.063155Z","iopub.execute_input":"2024-02-07T23:24:15.063531Z","iopub.status.idle":"2024-02-07T23:24:15.070744Z","shell.execute_reply.started":"2024-02-07T23:24:15.063501Z","shell.execute_reply":"2024-02-07T23:24:15.069721Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"predit-label\nclasse \t 1-1 \t 1-0 \t 0-1 \t nb de fois predite / nb fois où il doit l'être\n0 \t 0.88 \t 0.02 \t 0.12 \t 2.86\n1 \t 0.89 \t 0.23 \t 0.11 \t 9.60\n2 \t 0.14 \t 0.00 \t 0.86 \t 0.29\n3 \t 1.00 \t 0.03 \t 0.00 \t 2.01\n4 \t 0.97 \t 0.59 \t 0.03 \t 10.88\n5 \t 0.67 \t 0.06 \t 0.33 \t 6.63\n6 \t 0.89 \t 0.13 \t 0.11 \t 8.57\n7 \t 0.43 \t 0.03 \t 0.57 \t 3.00\n8 \t 0.46 \t 0.05 \t 0.54 \t 4.85\n9 \t 0.94 \t 0.00 \t 0.06 \t 1.17\n10 \t 1.00 \t 0.38 \t 0.00 \t 10.29\n11 \t 0.79 \t 0.04 \t 0.21 \t 4.35\n12 \t 0.83 \t 0.29 \t 0.17 \t 12.09\n13 \t 0.37 \t 0.02 \t 0.63 \t 2.35\n14 \t 0.80 \t 0.07 \t 0.20 \t 4.96\n15 \t 0.96 \t 0.11 \t 0.04 \t 4.23\n16 \t 0.89 \t 0.11 \t 0.11 \t 7.27\n17 \t 0.98 \t 0.47 \t 0.02 \t 9.91\n18 \t 0.57 \t 0.03 \t 0.43 \t 4.40\n19 \t 0.91 \t 0.15 \t 0.09 \t 8.37\n20 \t 0.59 \t 0.02 \t 0.41 \t 3.59\n21 \t 0.61 \t 0.03 \t 0.39 \t 3.10\n22 \t 0.99 \t 0.15 \t 0.01 \t 4.24\n23 \t 0.53 \t 0.04 \t 0.47 \t 3.93\n24 \t 0.82 \t 0.05 \t 0.18 \t 4.72\n25 \t 0.99 \t 0.02 \t 0.01 \t 1.83\n26 \t 0.95 \t 0.03 \t 0.05 \t 2.18\n27 \t 0.99 \t 0.17 \t 0.01 \t 3.16\n28 \t 0.99 \t 0.08 \t 0.01 \t 4.88\n29 \t 0.76 \t 0.02 \t 0.24 \t 3.76\n30 \t 0.99 \t 0.27 \t 0.01 \t 4.62\n31 \t 0.84 \t 0.04 \t 0.16 \t 3.46\n32 \t 0.39 \t 0.00 \t 0.61 \t 0.89\n33 \t 0.91 \t 0.11 \t 0.09 \t 6.34\n34 \t 0.98 \t 0.30 \t 0.02 \t 8.62\n35 \t 0.89 \t 0.32 \t 0.11 \t 10.51\n36 \t 0.00 \t 0.00 \t 1.00 \t 0.19\n37 \t 0.88 \t 0.14 \t 0.12 \t 6.96\n38 \t 0.98 \t 0.48 \t 0.02 \t 8.80\n39 \t 1.00 \t 0.23 \t 0.00 \t 3.75\n40 \t 0.75 \t 0.05 \t 0.25 \t 4.61\n41 \t 0.88 \t 0.23 \t 0.12 \t 10.28\n42 \t 0.93 \t 0.06 \t 0.07 \t 6.16\n43 \t 0.46 \t 0.03 \t 0.54 \t 3.46\n44 \t 0.76 \t 0.01 \t 0.24 \t 2.21\n45 \t 0.83 \t 0.09 \t 0.17 \t 6.28\n46 \t 0.78 \t 0.07 \t 0.22 \t 4.33\n47 \t 0.81 \t 0.11 \t 0.19 \t 5.74\n48 \t 0.91 \t 0.25 \t 0.09 \t 11.67\n49 \t 0.97 \t 0.04 \t 0.03 \t 2.86\n50 \t 0.94 \t 0.21 \t 0.06 \t 6.83\n51 \t 0.99 \t 0.33 \t 0.01 \t 5.50\n52 \t 0.98 \t 0.02 \t 0.02 \t 2.56\n53 \t 0.91 \t 0.20 \t 0.09 \t 8.50\n54 \t 0.83 \t 0.05 \t 0.17 \t 6.00\n55 \t 0.99 \t 0.17 \t 0.01 \t 3.66\n56 \t 0.74 \t 0.02 \t 0.26 \t 3.50\n57 \t 0.98 \t 0.42 \t 0.02 \t 8.09\n58 \t 0.94 \t 0.11 \t 0.06 \t 6.48\n59 \t 0.98 \t 0.10 \t 0.02 \t 4.87\n60 \t 0.99 \t 0.31 \t 0.01 \t 5.34\n61 \t 0.80 \t 0.03 \t 0.20 \t 3.06\n62 \t 0.95 \t 0.18 \t 0.05 \t 6.96\n63 \t 0.71 \t 0.11 \t 0.29 \t 6.53\n64 \t 0.97 \t 0.07 \t 0.03 \t 4.07\n65 \t 0.99 \t 0.49 \t 0.01 \t 7.33\n66 \t 0.80 \t 0.02 \t 0.20 \t 3.05\n67 \t 0.84 \t 0.22 \t 0.16 \t 7.63\n68 \t 0.97 \t 0.56 \t 0.03 \t 11.37\n69 \t 1.00 \t 0.07 \t 0.00 \t 2.67\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}